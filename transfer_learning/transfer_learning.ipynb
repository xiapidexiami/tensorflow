{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "681bb570-931c-4472-d164-e24ec2eb6de8"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
        "                               include_top=False,\n",
        "                               weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable=False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-09 03:59:20--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   138MB/s    in 0.6s    \n",
            "\n",
            "2019-10-09 03:59:21 (138 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3556fbf2-4e3d-48df-d055-08d3cb9a50c1"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc8dcc44-940a-4f95-cded-adce24211fe9"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics =['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1009 04:08:44.064400 139839724111744 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7263f29a-a3fe-4af2-8c0d-d6e535b28ba9"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-09 04:09:50--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  39.2MB/s    in 3.6s    \n",
            "\n",
            "2019-10-09 04:09:54 (39.2 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-10-09 04:09:56--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  26.2MB/s    in 0.4s    \n",
            "\n",
            "2019-10-09 04:09:57 (26.2 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "aac49432-b86a-4102-d736-f4e94d14e0bf"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses/'\n",
        "train_humans_dir = '/tmp/training/humans/'\n",
        "validation_horses_dir = '/tmp/validation/horses/'\n",
        "validation_humans_dir = '/tmp/validation/humans/'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8665e1cd-9d2b-4bf1-b377-c01db16ff11d"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   target_size=(150,150),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150,150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7d6d463-4677-44c4-94c9-dd5b8b739a9e"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                             steps_per_epoch=51,\n",
        "                             epochs=100,\n",
        "                             validation_data=validation_generator,\n",
        "                             validation_steps=12,\n",
        "                             verbose=1,\n",
        "                             callbacks=[callbacks])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.2587 - acc: 0.8977Epoch 1/100\n",
            "51/51 [==============================] - 17s 325ms/step - loss: 0.2613 - acc: 0.8967 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9656Epoch 1/100\n",
            "51/51 [==============================] - 15s 285ms/step - loss: 0.0865 - acc: 0.9662 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9726Epoch 1/100\n",
            "51/51 [==============================] - 15s 285ms/step - loss: 0.0623 - acc: 0.9732 - val_loss: 8.5038e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9787Epoch 1/100\n",
            "51/51 [==============================] - 14s 280ms/step - loss: 0.0618 - acc: 0.9782 - val_loss: 0.0325 - val_acc: 0.9875\n",
            "Epoch 5/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9858Epoch 1/100\n",
            "51/51 [==============================] - 14s 275ms/step - loss: 0.0477 - acc: 0.9861 - val_loss: 1.5690e-04 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9878Epoch 1/100\n",
            "51/51 [==============================] - 14s 275ms/step - loss: 0.0425 - acc: 0.9881 - val_loss: 0.0040 - val_acc: 0.9958\n",
            "Epoch 7/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9940Epoch 1/100\n",
            "51/51 [==============================] - 14s 276ms/step - loss: 0.0206 - acc: 0.9941 - val_loss: 0.0199 - val_acc: 0.9958\n",
            "Epoch 8/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9825Epoch 1/100\n",
            "51/51 [==============================] - 14s 272ms/step - loss: 0.0771 - acc: 0.9819 - val_loss: 2.9501e-04 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9848Epoch 1/100\n",
            "51/51 [==============================] - 14s 279ms/step - loss: 0.0401 - acc: 0.9851 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9890Epoch 1/100\n",
            "51/51 [==============================] - 14s 277ms/step - loss: 0.0260 - acc: 0.9892 - val_loss: 0.0046 - val_acc: 0.9958\n",
            "Epoch 11/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9887Epoch 1/100\n",
            "51/51 [==============================] - 14s 273ms/step - loss: 0.0298 - acc: 0.9889 - val_loss: 0.0072 - val_acc: 0.9958\n",
            "Epoch 12/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9930Epoch 1/100\n",
            "51/51 [==============================] - 14s 278ms/step - loss: 0.0219 - acc: 0.9931 - val_loss: 0.0127 - val_acc: 0.9917\n",
            "Epoch 13/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9887Epoch 1/100\n",
            "51/51 [==============================] - 14s 272ms/step - loss: 0.0322 - acc: 0.9889 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9920Epoch 1/100\n",
            "51/51 [==============================] - 14s 276ms/step - loss: 0.0270 - acc: 0.9922 - val_loss: 0.0489 - val_acc: 0.9917\n",
            "Epoch 15/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9856Epoch 1/100\n",
            "51/51 [==============================] - 14s 271ms/step - loss: 0.0493 - acc: 0.9859 - val_loss: 0.0108 - val_acc: 0.9958\n",
            "Epoch 16/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9920Epoch 1/100\n",
            "51/51 [==============================] - 14s 284ms/step - loss: 0.0286 - acc: 0.9922 - val_loss: 0.0628 - val_acc: 0.9875\n",
            "Epoch 17/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9949Epoch 1/100\n",
            "51/51 [==============================] - 14s 271ms/step - loss: 0.0096 - acc: 0.9950 - val_loss: 0.3067 - val_acc: 0.9667\n",
            "Epoch 18/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9787Epoch 1/100\n",
            "51/51 [==============================] - 14s 273ms/step - loss: 0.0730 - acc: 0.9791 - val_loss: 0.2005 - val_acc: 0.9750\n",
            "Epoch 19/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9848Epoch 1/100\n",
            "51/51 [==============================] - 14s 276ms/step - loss: 0.0470 - acc: 0.9851 - val_loss: 0.0588 - val_acc: 0.9833\n",
            "Epoch 20/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9919Epoch 1/100\n",
            "51/51 [==============================] - 14s 277ms/step - loss: 0.0241 - acc: 0.9921 - val_loss: 0.1202 - val_acc: 0.9792\n",
            "Epoch 21/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9939Epoch 1/100\n",
            "51/51 [==============================] - 14s 274ms/step - loss: 0.0144 - acc: 0.9940 - val_loss: 0.1748 - val_acc: 0.9792\n",
            "Epoch 22/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9950Epoch 1/100\n",
            "51/51 [==============================] - 14s 277ms/step - loss: 0.0242 - acc: 0.9951 - val_loss: 0.0982 - val_acc: 0.9833\n",
            "Epoch 23/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9959Epoch 1/100\n",
            "51/51 [==============================] - 14s 274ms/step - loss: 0.0152 - acc: 0.9960 - val_loss: 0.0837 - val_acc: 0.9833\n",
            "Epoch 24/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9939Epoch 1/100\n",
            "51/51 [==============================] - 14s 276ms/step - loss: 0.0218 - acc: 0.9940 - val_loss: 0.1371 - val_acc: 0.9833\n",
            "Epoch 25/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9938Epoch 1/100\n",
            "51/51 [==============================] - 14s 270ms/step - loss: 0.0279 - acc: 0.9940 - val_loss: 0.1812 - val_acc: 0.9792\n",
            "Epoch 26/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9959Epoch 1/100\n",
            "51/51 [==============================] - 14s 282ms/step - loss: 0.0075 - acc: 0.9960 - val_loss: 0.2185 - val_acc: 0.9708\n",
            "Epoch 27/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9970Epoch 1/100\n",
            "51/51 [==============================] - 14s 275ms/step - loss: 0.0136 - acc: 0.9970 - val_loss: 0.1939 - val_acc: 0.9792\n",
            "Epoch 28/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9960Epoch 1/100\n",
            "51/51 [==============================] - 14s 278ms/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.3279 - val_acc: 0.9708\n",
            "Epoch 29/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9919Epoch 1/100\n",
            "51/51 [==============================] - 14s 275ms/step - loss: 0.0204 - acc: 0.9921 - val_loss: 0.2919 - val_acc: 0.9708\n",
            "Epoch 30/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9908Epoch 1/100\n",
            "51/51 [==============================] - 14s 272ms/step - loss: 0.0249 - acc: 0.9909 - val_loss: 0.3731 - val_acc: 0.9625\n",
            "Epoch 31/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9980Epoch 1/100\n",
            "51/51 [==============================] - 14s 277ms/step - loss: 0.0194 - acc: 0.9980 - val_loss: 0.4002 - val_acc: 0.9625\n",
            "Epoch 32/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9949Epoch 1/100\n",
            "51/51 [==============================] - 14s 273ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.3489 - val_acc: 0.9667\n",
            "Epoch 33/100\n",
            "50/51 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9990Epoch 1/100\n",
            "12/51 [======>.......................] - ETA: 4s - loss: 0.3640 - acc: 0.9667\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "51/51 [==============================] - 14s 273ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.3640 - val_acc: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "ef75da6b-5717-4bd6-acd4-0aa83c1b3d46"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJztnXd4VNXWh99FE5BeVAQRbEAoQQhF\nASmKYgNFFAEvggI2ULBc21UsFysgtouigmKhiBcrNoofYqMHFKSIeOkCgdBETLK+P/aZOAlJpmRS\nZma9zzNPZs7ZZ591dmZ+Z5+1115bVBXDMAwjPihR1AYYhmEYhYeJvmEYRhxhom8YhhFHmOgbhmHE\nESb6hmEYcYSJvmEYRhxhoh+HiEhJETkgInUjWbYoEZHTRCTi8ccicp6IbPT7vEZEOgRTNoxzvSoi\n94V7vGEEQ6miNsAIjIgc8PtYHvgTSPc+36Cqb4dSn6qmAxUiXTYeUNUGkahHRAYB16hqJ7+6B0Wi\nbsPICxP9KEBVM0XX60kOUtXZuZUXkVKqmlYYthlGIOz7WLww904MICL/FpFpIjJFRPYD14jIWSLy\nvYjsFZFtIvKciJT2ypcSERWRet7nt7z9n4rIfhH5TkTqh1rW23+hiKwVkVQReV5EvhGRAbnYHYyN\nN4jIehHZIyLP+R1bUkSeEZHdIrIB6JZH+9wvIlOzbXtRRMZ67weJyGrven7xeuG51bVZRDp578uL\nyJuebT8BLbOV/ZeIbPDq/UlEunvbmwIvAB0819kuv7Z9yO/4G71r3y0i74tIrWDaJpR29tkjIrNF\nJEVEtovIP/3O84DXJvtEZLGInJiTK01EFvj+z157zvfOkwL8S0ROF5F53jl2ee1W2e/4k71r3Ont\nf1ZEyno2N/IrV0tEDolI9dyu1wiAqtoril7ARuC8bNv+DRwBLsXdyMsBrYA2uKe5U4C1wFCvfClA\ngXre57eAXUASUBqYBrwVRtnjgP1AD2/f7cBfwIBcriUYGz8AKgP1gBTftQNDgZ+AOkB1YL77Oud4\nnlOAA8CxfnX/DiR5ny/1ygjQBfgDaObtOw/Y6FfXZqCT93408BVQFTgZWJWt7FVALe9/0tez4Xhv\n3yDgq2x2vgU85L0/37OxOVAW+A8wN5i2CbGdKwM7gNuAY4BKQGtv371AMnC6dw3NgWrAadnbGljg\n+z9715YG3ASUxH0fzwDOBcp435NvgNF+1/Oj157HeuXbefsmAKP8znMHMLOof4fR/CpyA+wV4j8s\nd9GfG+C4O4F3vfc5CflLfmW7Az+GUfY64Gu/fQJsIxfRD9LGtn77/wvc6b2fj3Nz+fZdlF2IstX9\nPdDXe38hsCaPsh8Dt3jv8xL9//n/L4Cb/cvmUO+PwMXe+0Ci/wbwmN++SrhxnDqB2ibEdv4HsCiX\ncr/47M22PRjR3xDAhl6+8wIdgO1AyRzKtQN+BcT7vBzoGenfVTy9zL0TO2zy/yAiDUXkE+9xfR/w\nCFAjj+O3+70/RN6Dt7mVPdHfDnW/0s25VRKkjUGdC/gtD3sB3gH6eO/7ep99dlwiIj94roe9uF52\nXm3lo1ZeNojIABFJ9lwUe4GGQdYL7voy61PVfcAeoLZfmaD+ZwHa+SScuOdEXvsCkf37eIKITBeR\nLZ4Nr2ezYaO6oIEsqOo3uKeG9iLSBKgLfBKmTQbm048lsocrvozrWZ6mqpWAB3E974JkG64nCoCI\nCFlFKjv5sXEbTix8BAopnQ6cJyK1ce6ndzwbywEzgMdxrpcqwBdB2rE9NxtE5BRgPM7FUd2r92e/\negOFl27FuYx89VXEuZG2BGFXdvJq503Aqbkcl9u+g55N5f22nZCtTPbrexIXddbUs2FANhtOFpGS\nudgxGbgG91QyXVX/zKWcEQQm+rFLRSAVOOgNhN1QCOf8GGghIpeKSCmcn7hmAdk4HRguIrW9Qb27\n8yqsqttxLojXca6ddd6uY3B+5p1AuohcgvM9B2vDfSJSRdw8hqF++yrghG8n7v43GNfT97EDqOM/\noJqNKcD1ItJMRI7B3ZS+VtVcn5zyIK92/hCoKyJDReQYEakkIq29fa8C/xaRU8XRXESq4W5223EB\nAyVFZAh+N6g8bDgIpIrISTgXk4/vgN3AY+IGx8uJSDu//W/i3EF9cTcAIx+Y6McudwDX4gZWX8YN\nuBYoqroD6A2Mxf2ITwWW4Xp4kbZxPDAHWAkswvXWA/EOzkef6dpR1b3ACGAmbjC0F+7mFQwjcU8c\nG4FP8RMkVV0BPA8s9Mo0AH7wO/ZLYB2wQ0T83TS+4z/DuWFmesfXBfoFaVd2cm1nVU0FugJX4G5E\na4GO3u6ngfdx7bwPN6ha1nPbDQbuww3qn5bt2nJiJNAad/P5EHjPz4Y04BKgEa7X/z/c/8G3fyPu\n//ynqn4b4rUb2fANjhhGxPEe17cCvVT166K2x4heRGQybnD4oaK2JdqxyVlGRBGRbrhImT9wIX9/\n4Xq7hhEW3vhID6BpUdsSC5h7x4g07YENOF/2BcDlNvBmhIuIPI6bK/CYqv6vqO2JBcy9YxiGEUdY\nT98wDCOOKHY+/Ro1ami9evWK2gzDMIyoYsmSJbtUNa8QaaAYin69evVYvHhxUZthGIYRVYhIoFnp\ngLl3DMMw4goTfcMwjDjCRN8wDCOOMNE3DMOII0z0DcMw4oiAoi8iE0XkdxH5MZf94i2Ltl5EVohI\nC79914rIOu91bSQNNwzDMEInmJ7+6+Sx/ihuFaLTvdcQXPZDvBSsI3HLtLUGRopI1fwYaxiGYeSP\ngHH6qjpfvEWxc6EHMNlLt/q9l1u8FtAJ+FJVUwBE5EvczWNKfo3OiYMH4cknI1dfyZIwaBDUzmsJ\nkCCZNg2SkuDU3JaqiDA//wxTp0JGRt7lSpSA3r2hUaO8yxU2H34ITZtC/fqByxqGERqRmJxVm6xL\no232tuW2/Si8RRiGANStG2gBpJw5dAj+/e+wDs0RVdi6FV5+OX/1LFkCV18NVavCjBnQpUtk7MuN\nWbPc+fbvBwmw9pMqjB3rbhAXXVSwdgXLN99Ajx5O9JcuhVLFbvqgYUQ3xWIgV1UnqGqSqibVrBlw\nFnGO1KzperaReg0cCO+848QzP0yYAOXKQa1acMEF7nNBoArjxsGll8Jpp8GmTYGvcdMmV/bSS+GZ\nZ1wdRUl6OtxyC1SoACtXwvjxRWuPYRQqr7wCTz1V4KeJhOhvIes6oXW8bbltjwqGDIEDB1wvOFwO\nHHA3jt694bvvoGtXuOEGGD4c0tIiZ+tff8GNN8KIEa6X/PXXUKdO4OPq1HFlL7sMbr/d2XbkSOTs\nCpWXXoLkZJg40bXVAw/Ajh1FZ49hFAp//ul+fEOGwFdfBfbL5hdVDfgC6gE/5rLvYtxScQK0BRZ6\n26sBv+IWc67qva8W6FwtW7bU4kBGhmqTJqqtWoVfxyuvqILqt9+6z3/9pTp8uNt24YWqe/fm387d\nu1U7d3Z13nefanp66HWkp7tjQbVTJ1dnYfP776pVqqiee65r+59/Vi1dWnXgwMK3xTCCZuxY1dtv\nV01JCe/4rVtVzzrL/fjuuUc1LS1sU4DFGoyeByzgBl634VZA2gxcD9wI3OjtF+BF4BfcOpZJfsde\nB6z3XgODMai4iL6q6nPPuRZaujS841u1Um3c2ImYPy+9pFqqlGpCguqGDeHbt2aN6umnq5Ypozp5\ncvj1+Jg82dV12mlOdAuT6693bbJq1d/b7r47603TMIoVX3zhvqCgWrOm6qRJofW6vv1WtVYt1WOP\nVZ0+Pd/mREz0C/tVnEQ/JUW1bFnVm24K/dilS13rPvtszvvnzFGtWlW1Rg3Vr78Ovf7Zs13PuGZN\n1QULQj8+NxYscHVWqaL65ZeRqzcvvv/etdWdd2bdvn+/au3aqi1a5KsDZEQjGRmqv/zixPDuu1XP\nP1+1b1/3pQzncTbS7N6teuKJqo0aqX73nerZZ7svcbt2qsuXBz7+5Zfdo+ypp6quXBkRk0z0I0T/\n/qoVK6oeOBDacTfd5G4YeblK1qxRPeMM17t+443g637pJdWSJd1TxK+/hmZXMPz6q3NtlSypOn58\n5Ov3Jy1NtWVL1+HZt+/o/VOnum9pQdthFCHZBf6881yPyNeLLl1a9cwz/95Wr57qww+r/vZb0dl7\n5ZXu0XTJErctPV114kTXiytZUvW221RTU48+9vBh1cGD3XVccEH4bqEcCFb0i91yiUlJSVqc8ukv\nWAAdOsBrr8F11wV3zMGDcOKJblB18uS8y+7ZA716wdy5cM01gecF/Pbb3yGWU6ZApUrB2RQq+/ZB\n377wySduIDrQuja+mP/ExNDOM2GCG8N6+213vuyowrnnwvLlsHYt1KgRfN2q8Oabbo5EQkJodsUN\n27e70fPly91rxQr3JRw82H2By5QpuHOvWuVCtKZMgd273bbSpV28bsuW7pWUBE2awDHHwOHD8P77\n7sc4e7aLST7/fLj+euje3ZUpDN58E/r3h8ceg3vvzbovJQXuv9/Feh9/PIwZA336OFu3bnU/9u++\nc8c9+qibEBQhRGSJqiYFLBjMnaEwX8Wtp5+R4Z7g2rYN/piJE92NfP784MofOaI6dKhquXKqxxyT\n96t8edU77igcd0damnO5lC8f2K6SJZ39774bfP27dqlWq6basePR4x7+/Pij61QNGRJ83YcOqfbp\n4/4PZ5yh+uefwR8bk6Snq65erTpliutNX3CB6vHH/92bBtWTT1a95BLVunXd5+OOc2XXrYucHUeO\nuC9Jp07uHGXKqF59tXt8XbzY9YSD4ddfVR98UPWkk1w91au7KIkIuUryPG/Fiqrt2+f9I1y4UDUp\nSTOjI955R/WEE5z/PpQfSQhg7p3I8cwzrqWSk4Mr37atasOGeQtZrLF9+99BCI8+Gty133iju1ms\nWBG47O23q4qoLloUuOy2bapt2jhb+vVzf594IvBxefL1187t8Npr+ayokNiyRXXmTBcR0qWLEyp/\nd0nz5qoDBqiOG6c6b15WN0NamuqsWaqXXeb+QeDCqqZPD//uuWWL6siRzo/nu8E88YQL28oPaWmq\nn36q2quXuy5QvfZa1R078ldvbufq0MG1ZTB+1bQ0dzPzuaUi6L/PCRP9CLJrl+vNDh0auOyKFa5V\nx44tIGO2bCm2o5p//PG3yPbt6z7nxuLFTsRvuy24ulNTXUepdeu8x/GWL3edv/LlVf/7X7ete3fX\nwdq0KfhryWTDBue/9QlmQkIYlRQwBw444X7iCdWePVXr1Pnb3lKl3KDJTTe5R9Dly0MT7s2b3V3c\n1/uvWVP1n/904rV9u/tx7N3rbDh82H03fXf8jAzVuXOdIPtuHt26qX70UcF8h3//XfXee534V63q\nBDeSg75PPOGu4fXXQ7frhRci6r/PCRP9CNO3r2rlyqoHD+Zdbtgw98S6a1cBGDFnjvsR33tvAVQe\nGTIyVEeNct+stm2dLmQnPd3tO/740OYqvPmmq/fVV3Pe/8EHTtzr1MkaZrthgxtU7907hAtJTXWu\njTJl3B3koYdUH3/cGbBmTQgVFRAZGe6xZ9Agd9E+kT/1VOfXGjfOhQQeOhSZ8+XU+8/rVaqUaztw\nPrw771Rdvz4ytgRi1aq/3UetW4cfc+3P0qXuZtKrV7F9hDfRjzBffRX4Jn/woAt17Nu3AAxYv979\neHz+y7y60cWAGTOcj79uXT+32O7dqnPn6sTXMhRCi1hSdb+19u1dgIR/VFRGhuqTT7onh1at3HyX\n7Dz0kGu6uXMDnOSvv1wPsWZNd0D//q63q+qiRcCdrKhITXWhTGee6WwpX95Ncpg1q4B6GjmwZYtz\nc734ootJHjPGtcmoUS6q5oEHXMfkrrvcDyZSN55QyMhwvYTjjlMtUUL11ltzjqYJhkOH3MBerVqF\n18ZhYKIfYTIy3IBgu3a5l3njDdei8+ZF+OSpqc6tUK2ai+8F1bfeivBJIs/ixS6UuUIF1Q//s0n1\nlFM0hSpas+w+PfusjLCevJcvd7/hm292nw8fdq5pUL3qqtz15dAh1fr1XTMeOZJL5V984WJVwd1d\nchpAaNnSDV4UJhkZbmDQv1efmKj6n/9EZlp3LJOS4r4sIk60p04Nvad+662uzT//vGBsjBAm+gXA\n6NGuxX78Mef97dq5GbIRffpLS3MRFSVLOvdOero7Sfv2ETxJwbFli2rL01NVSNenK4zUoY1mawnS\ndFnbG1X37AmrzmHDVEuUyNAv7vxcO3RwTw0jRwZu9w8+cP+/MWOy7di6VfXii93O+vVddEVulT36\nqCuX0+NEpDlyxPXqmzfP2qv/4Ydi62Iotixc6G7YoNq1q5tQlevd34/PP3fH3HprwduYT0z0C4Df\nf3duvZwGH3/6ybXm009H+KS+XAQvvvj3Nt/dp6DD0yLBSy/pwRIVtFelzzPdvbd0/sn5fBs1cpNy\nQuGvv3TPyGe0JjsUVI8p9ZdOmRLcoRkZqhdd5IIvMjX7jz+cT6h8eeeiCOQ2+/FHdxEvvRSa3eFw\nyy1Ze/XhuicMR1qa6vPPq1aq5Nq1bFnXebrrLjfqv21b1vK7drmng4SEonFRhYiJfgHRu7cLDMj+\nHRg+3N0Q8huBlgXfyOWNN2bdvnNn8OFERUVamuqIEerLLpe+J1VHjnShy7t3q3Ou+/JQBJtHYtky\nl5MB9N02T2mTShv1e9qofvZZ0GatW+fGF/v1U3cXGDjQ2ThzZnAVZGS45ETdugV9zrD46CNn1/Dh\n1quPNLt2ufDTESNcRIFvwNn3pNe3r7s5dO/uftSRGAguBEz0C4g5c1yrvfnm39v++MPp11VXRfBE\nP/zghL1jx5wfQ6+5xvVYQs0PURjs36966aWa+Vj81185l/PPGJfXGMUff7g0oCVLupCfGTPc9gMH\nVJs1c40fwhPD/fc70/5vxEz35oEHQrg4dZEopUsXnD992zZ3M0xMDH6ykhE+f/yh+s037gn6iivc\nQJTvJpDvCR6Fh4l+AZGe7jp655zz97a33nItOXt2hE6yebN7rKxf3/Xqc2LBAs0zfrGo+N//nFiV\nLJnVJZUbu3e7G5tPfLOP7i5YoNqggds/YMDRyYzWr3ei36xZ0DfAgwdV6x7/hzZlhf7V7ZLQY7m/\n+cbZE6xfKRTS091s2bJlnc/QKHwyMlyklm8MLUow0S9AfHM0Vq92nzt2dOHREfl+HDrkfCAVKuTt\ns/cl/E9KisBJI8TChW4GVaVKIblc9M8/Va+7TrOE4Ozb59xXIm72Zl6RE5995spdfXVwrpAtW/S9\nKtcpqD77RICJFzmRluaeOCL6aOfhm/79n/9Evm4jpjHRL0C2b3fjkLff7vLOR+wpMCPDTawRcaEm\ngXjhBXfyYHIThGvP2LFuwLVFC7day2WXudj1YcOcn+Spp9yg5pgxLjC/Xr3cw5sCneupp9y1t2zp\nAvxFnHto//7Ax/smTo0enXe5w4dVzzpLM8ofq13P2q+VKuU8gSwggwe7G3Mk3S/LlztXV/fu5sc3\nQsZEv4Dp1cvNkbrlFncDCEs4svPYY+5f8thjwZXfu9dFnQwaFIGTZ+PwYZfDxJcj/OKLXaRDs2au\n5121qguY95+FefbZ+R/JnjnTXVPDhs6NEiwZGe6fUqJE3gsB3HCDs/XddzNX5xowIAw7Z81y9cya\nFcbBOXDokIsSOeGECEcDGPGCiX4B4wvfBTf2ky+2bXMzGUVcTz+UXt6gQU4kIzmo6J897eGHc7cn\nI8P50bdsUV27NnL5VHbtCi6GOjv797tFBqpXzzkh1oQJ7pruuSdzU9ircx0+7Hr6gweHbmdO3Hyz\nM+SLLyJTnxF3mOgXMOnpzpMR9kS99HT3A7/iCveoAK43HWo88OLF7tjnnw/DiBxYutRlLAs1T3Jx\nYe1alySpefOsiZK++865Ts4/P8vNybc615lnhjEmc9VVbpp/fm92H37o/oe3356/eoy4xkS/EHjt\nNachIYnFtm3OfVO/vmbm0bnjjvwtSpuUlPNivKEyY4Z7asiesSza+Phj99R0zTWuTbZtc2F49evn\nuJSZbwH7ZctCPM+UKe7A/KxXuXWrC89s3tzCM418YaJfnEhPd48D/r1638IKkfihv/qqqzOcxXZV\nnTA+8ohmpsbMPjMxGvFdz9NPu7GIcuVyXbvUl0ftuedCPMfevW5QIPvivsGSnu56DeXKZV0R3jDC\nwES/uLB3r2rTpq6pa9RwApGfXn1OHDjgXBr9+oV+7MGDzk3hyyhZzLN3Bk16umqPHpo58PLOO3kW\nr1vXpc0PmW7dXLxuOE9ZY8c622wBYCMCmOgXF265xUWUTJpUsI/vvkT+uU3myolNm1x4pIgLl4y1\nMMHUVLfS0UMPBSzar58LnAm5CV56ScPKg7Rsmft/9egRe+1uFAnBin6JiK3KaxzNDz/Af/4DQ4fC\ngAEFu3DzDTfAkSPw+uuBy6rCjBlu4ek1a+DDD+Guu9zizbFEpUowfz6MHBmwaIcObo3wX34J8Rzd\nu7t2e//94I9JTYWrr4bq1eHVV2Ov3Y1ijYl+QfHXXzBkCJx4olv1vqBp3Ngp18svQ0ZG7uW2boWe\nPeHKK6FOHfj+e7jkkoK3r5jToYP7+/XXIR5Yqxa0bRu86KelQe/e7u4yZQrUqBHiCQ0jf5joFxTP\nPgsrVsALL7geZ2Fw442wfj3MnXv0PlXXq0xIgM8+g6eeck8ijRsXjm3FnEaNXMc7ZNEHuOwyWLIE\n/ve/wGXvvBM+/xzGj4eOHcM4mWHkD3GuoOJDUlKSLl68uKjNyB8bNzox7do1tMf+/PLnn6733rGj\nc9/4+OUX99Qxd67b98orcPrphWdXlHDZZfDTT7BuXYgHrl0LDRrAc8/BsGG5l5swwbnhhg9nUrNn\nqFULunXLl8lBs26d64f8+Wdk6qtcGe65xx5UihMiskRVkwKVK1UYxsQVqnDLLc5P+/zzhXvuY46B\ngQNh7FjnxjnuOPdLf+ABKF0aXnoJBg+GEvaAlxMdOsAHH8C2bc5rEzRnnOGeoGbOzF30581z34sL\nL+S7nk9z3Tlu82OPOfEsSLf+3LnQqxccPgxVq0amzt9/d5f78cfuKcmIIoIZ7S3MV9RH77z7rovm\neOaZojn/unXu/AMHuklb4HLbb9pUNPZEET/84Jpr2rQwDvbl+89p4ey1a12uokaNNG33Xm3Rws0C\nvvrqvyNlCyqw66WX3NSQxo1VN2yIXL3ffecSjYaaUNUoOLCQzSJg716XB79Fi9wXDikMunZ1/9qa\nNcNbCDpOOXLETUgOa0GyRYtcm7/xRtbte/a49QCqV1ddv17Hj3fFfP8W3xyydu1Ud+yIyGWoqvv6\n3Xab+hYuK5CVFn/7zeXfK1EicllAjPCJqOgD3YA1wHrgnhz2nwzMAVYAXwF1/PY9BfwErAaewxtH\nyO0V1aLvi8lfvLho7Vi+3CUVy6nXaeTJeee5NWBCJiPDdd8vu+zvbX/95Wbcliql+tVXunOn6/B3\n7pz1PjxtmlszpV69yCx7vHevE3rfaosF2f/Yv99lggaXMy6cPHlGZIiY6AMlgV+AU4AyQDKQkK3M\nu8C13vsuwJve+7OBb7w6SgLfAZ3yOl/Uiv5337lJTjmtmm5EDb5kp3v2hHHwLbe4lAq+RG/Dhqn/\n6maDBzv9z2m5gYUL3UNihQoudVC4/PKLy9BcqlThrN2u6vLN3XWXu9TzzlNNSSmc8xpZiaTonwV8\n7vf5XuDebGV+Ak7y3guwz+/YJUA5oDywGGiU1/miUvSPHHHPubVruxWfjKhl7lz3q/jkkzAOnj1b\nMxdZ9/lxRoxQVSfqInkn0ty0yWX7LFHCZWgI1Ss3f77L9FG1qlvpr7CZONGlImrQwA1jGIVLJEW/\nF/Cq3+d/AC9kK/MOcJv3viegQHXv82hgL5AKjAp0vqgU/aee+vvHbkQ1Bw864fJLuR88R46oVqni\nxnRKllS96CLVtDRNT1dt3dqleQjkWz9wQLVnT/d1GjzYrSQZDJMmObvPOMOtN19UzJ/vhi+qVnU3\nUKPwCFb0IxWyeSfwgogMAOYDW4B0ETkNaATU8cp9KSIdVDXLFBgRGQIMAahbt26ETCokNm500/x7\n9HCB3kZUU768y04R1iSt0qXd7Oa33nIhnFOmQMmSTHwVFi6EN98MPE/v2GPh3XddlO1jj8GyZYFD\nIvfuhY8+gi5d3PSMSIVlhkOHDu5aL7kEzj8f3ngD+vbNf73Tp0OFCnDRRfmvK94JODlLRM4CHlLV\nC7zP9wKo6uO5lK8A/KyqdUTkLqCsqj7q7XsQOKyqT+V2vqianKXqvt3/93+wejWcdFJRW2REgH/+\n001vSE2FsmVDPPj7792s28mT4ZRTSEn5O4z///4vtHj8t96Cf//bpVQKRI8ebpJ16dIh2ltApKa6\nn0ZyskvvFNK8h2ysWgWJiVCmDPz8s/3MciPYyVnBuHdKARuA+vw9kNs4W5kaQAnv/SjgEe99b2C2\nV0dpXITPpXmdL6rcO2+8oUUak28UCL6FrP7v//Jf1803Ox99cnL+64o21q1ziUSvuSb8OjIyVM89\n12UOL1vWZQE3coZIZdlU1TRgKPA5Luxyuqr+JCKPiEh3r1gnYI2IrAWO94QfYAYu8meld7NIVtWP\nAt6JooH33oPrr3fPs0OHFrU1RgRp1879DcvF48eyZW4S9C23QLNm+bcr2jjtNJe89a23wm/LGTNg\nzhwYNQruvde5eebMiayd8Ybl3gmH995zqXFbt3bJyypWLGqLjAjTtCnUru3+veGQkeH6A+vXO/dG\nlSqRtS9aOHTIjUlUrgxLl0KpEEYRDxxwx9aoAYsXu8S1jRu7bCPLlzt3j/E3wbp3LAlLqLz3nkuN\na4If03ToAN9+6zIhh8Obb7rjn3wyfgUf3MD42LGwcqVLLBoKjz0Gmze7RLUlS7rxlWefdcNnhZ3W\nKqYIxgdUmK9i7dOfMcOF4p19tsXjxzjvvOP8+uFMrt67V/W441TPOsut2hjvZGS4zCCVK6tu3x7c\nMWvWuBDU/v2P3nfxxW4S25YtkbUz2sFWzoowvh5+mzbWw48Dwl5UBRfBu3On66FaQtO/E84eOuQy\nigZCFW69FcqVcxFJ2Xn2Wedgck5nAAAfcklEQVTqueuuyNsaD9hXMhhmzDDBjzPq1IF69UIX/ZUr\nndjfeCO0aFEgpkUlDRrAiBFuNc/vvsu77AcfuHVmHnkEjj/+6P2nnurCat95x62GaYSGDeQGYsYM\nN2hrgh939O/v/uU7dgQXX68KnTq5hVjWroVq1QrcxKjiwAFo2NAJ+cKFzk+fnUOH3JyGihVd9FNu\nA7++cpUqhT5AHKvYQG4kMMGPazp0cG6atWuDKz9liut5Pv64CX5OVKgAY8Y4kX7llZzLPPkk/Pab\ne1rKS8jLl4dnnnFPVv/5T8HYG6tYTz83TPDjnp9/diGDr7wCgwblXXbfPteL9a01b778nFGFc891\nIZdr12ZdbvGXX1xIZs+eznUTTF3durn2Xrs2Z1dQPGE9/fywcCH06WOCH+c0aAA1awbn13/0Udi+\nHV580QQ/L3yDuvv3w333Zd03fLhLIzF6dGh1/fEH3H135G2NVezrmZ39+12GqFq13AKgJvhxi4hz\n8QQS/VWrYNw4N0G7VavCsS2aadzYRee8+iosWuS2ffyxe40cCSeeGHxdZ5wBd9zhErt9+23B2Btr\nmHsnOwMHumRZ8+bBOecUnR1GsWDcOBd1snmzm6GbHVU47zw36JjdXWHkzr597kmqbl33U2va1M2w\nTU4Ofaatb+ZuzZruJpLTAHE8YO6dcJg+3cWU3XuvCb4BBI7XnzED5s512TBN8IOnUiV4+mnnSe3S\nBTZscIO34aRW8A0QL1sGL78ceVtjDevp+/jf/1xWrIYN3S+8uOSoNYqUtDSXn75/f+ev9yd7bph4\n7WGGi6rrWy1YAFde6fpc+anrvPPc/+HccwOXv+oqF6cRSwTb07foVoD0dLjmGvf37bdN8I1MSpWC\ns8/Ouac/apRz+0ybZoIfDiIwYQL8618uP09+6xo/3kVZrV+fd9mUFPjkE7dYzumn5++80YiJPsAT\nT7hf9euvu+l+huFHhw5uJauUlL/j79eudS6Fa691NwUjPBo1chlOIsEZZwQ3Q3fbNjeecNttTvxD\nWdgmFjCf/g8/uJCB3r3dM7xhZMPn1//mG/fXPzfMk08WnV1GeNSqBQ8/DJ9+Ch9+WNTWFD7xLfq+\n8Mzatd1qF/F2yzeConVr5/HzuXjefz/v3DBG8WfoUBc6Ony4i/OPJ+Jb9IcNcwubv/VWfCc9N/Kk\nXDkXf//11y7ny4gR0KSJWxHLiE5Kl3bRQhs3xt/TWvyK/rRpbkbHfff9/fxuGLnQoYOLDBk50uWG\nefFFS/IV7XTq5CJ4nnjChYzGC/Ep+r/9Bjfc4NIsPPhgUVtjRAEdOrjwzdGjnUfQpnHEBqNHu5v3\niBFFbUnhEX99lfR0+Mc/LDzTCIl27dyQz7HHuklFRmxQu7br9919N8yaBRddFPlzrFnjznHgQOCy\nDRrkP3w1EPEn+uPHO+fsG29YeKYRNFWquN7gmWeGlhvGKP4MHw6TJrmIrC5d3Fq8kWL2bDfxDOC0\n0wKXP+64yJ07N+JP9Jcscb/af/yjqC0xoowxY4raAqMgKFPGZevs2tX9j++/PzL1vvSSixJq1Ag+\n+sitxFYciD+f/u7dbt68hWcahuFx3nnQq5ebZf3bb/mrKy3NTfy66SaX7/+bb4qP4EM8in5KClSv\nXtRWGIZRzBgzxvUF77gj/DpSU+GSS+C555w78IMPXHK54kR8ir6tZWcYRjbq1nWunffegy+/DP34\nDRvgrLNgzhyXU2js2OKZk8lE3zAMw+OOO1wStmHD4MiR4I+bP9/N3N6+Hb74AgYPLjgb80t8ib6q\n8+mbe8cwjBw45hjnmlmzxi2gEwyTJrkxgerVXSqvzp0L1sb8El/ROwcOuFEW6+kbhpEL3bpBjx4u\nKVsgN8/hw249gPPOc+sBVK1aODbmh/jq6aekuL8m+oZh5MHzz7uY/UOH8n5lZPw9sSsaBB/irae/\ne7f7a6JvGEYenHSSi62PRYLq6YtINxFZIyLrReSeHPafLCJzRGSFiHwlInX89tUVkS9EZLWIrBKR\nepEzP0R8PX3z6RuGEacEFH0RKQm8CFwIJAB9RCQhW7HRwGRVbQY8Ajzut28y8LSqNgJaA79HwvCw\nMPeOYRhxTjA9/dbAelXdoKpHgKlAj2xlEoC53vt5vv3ezaGUqn4JoKoHVPVQRCwPBxN9wzDinGBE\nvzawye/zZm+bP8lAT+/95UBFEakOnAHsFZH/isgyEXnae3LIgogMEZHFIrJ4586doV9FsJhP3zCM\nOCdS0Tt3Ah1FZBnQEdgCpOMGijt4+1sBpwADsh+sqhNUNUlVk2rWrBkhk3IgJQXKl49sGj3DMIwo\nIhjR3wKc5Pe5jrctE1Xdqqo9VfVM4H5v217cU8FyzzWUBrwPtIiI5eFgs3ENw4hzghH9RcDpIlJf\nRMoAVwNZ1pAXkRoi4qvrXmCi37FVRMTXfe8CrMq/2WFis3ENw4hzAoq+10MfCnwOrAamq+pPIvKI\niHT3inUC1ojIWuB4YJR3bDrOtTNHRFYCArwS8asIFuvpG4YR5wQ1OUtVZwGzsm170O/9DGBGLsd+\nCTTLh42RIyUFErJHmxqGYcQP8ZWGwdw7hmHEOfEj+qrm3jEMI+6JH9G3DJuGYRhxJPo2G9cwDCOO\nRN83G9d8+oZhxDHxI/rW0zcMwzDRNwzDiCfiR/TNvWMYhhFHou/r6UfLmmaGYRgFQHyJvmXYNAwj\nzokf0bfZuIZhGHEk+jYb1zAMw0TfMAwjnjDRNwzDiCPiR/TNp28YhhEnom8ZNg3DMIB4EX3LsGkY\nhgHEi+jbbFzDMAwgXkTf8u4YhmEAJvqGYRhxRXyJvrl3DMOIc+JD9H0+fevpG4YR58SH6FuGTcMw\nDCCeRN8ybBqGYcSJ6NtsXMMwDCBeRN9m4xqGYQAm+oZhGHFFfIi+uXcMwzCAeBF96+kbhmEAQYq+\niHQTkTUisl5E7slh/8kiMkdEVojIVyJSJ9v+SiKyWUReiJThQWMZNg3DMDIJKPoiUhJ4EbgQSAD6\niEhCtmKjgcmq2gx4BHg82/5Hgfn5NzcMfBk2zb1jGIYRVE+/NbBeVTeo6hFgKtAjW5kEYK73fp7/\nfhFpCRwPfJF/c8PAZuMahmFkEozo1wY2+X3e7G3zJxno6b2/HKgoItVFpAQwBrgzrxOIyBARWSwi\ni3fu3Bmc5cFiydYMwzAyidRA7p1ARxFZBnQEtgDpwM3ALFXdnNfBqjpBVZNUNalmzZoRMsnDkq0Z\nhmFkUiqIMluAk/w+1/G2ZaKqW/F6+iJSAbhCVfeKyFlABxG5GagAlBGRA6p61GBwgWHuHcMwjEyC\nEf1FwOkiUh8n9lcDff0LiEgNIEVVM4B7gYkAqtrPr8wAIKlQBR/MvWMYhuFHQPeOqqYBQ4HPgdXA\ndFX9SUQeEZHuXrFOwBoRWYsbtB1VQPaGjom+YRhGJsH09FHVWcCsbNse9Hs/A5gRoI7XgddDtjC/\n7N4Nxx4LxxxT6Kc2DMMobsT+jFybmGUYhpGJib5hGEYcER+ib+GahmEYQDyI/u7d1tM3DMPwiH3R\nN/eOYRhGJrEt+r4Mm+beMQzDAGJd9Pfvdxk2radvGIYBxLro28QswzCMLJjoG4ZhxBHxIfrm0zcM\nwwBiXfQtw6ZhGEYWYlv0zb1jGIaRBRN9wzCMOCK2Rd8ybBqGYWQhtkXfZuMahmFkIfZF3yJ3DMMw\nMolt0bdka4ZhGFmIbdE3945hGEYWTPQNwzDiiNgVfcuwaRiGcRSxK/qWYdMwDOMoYlf0bWKWYRjG\nUcS+6Jt7xzAMI5PYFX1LtmYYhnEUsSv65t4xDMM4itgXfXPvGIZhZBK7ou9z71StWrR2GIZhFCNi\nV/RTUizDpmEYRjZiW/TNtWMYhpGFoERfRLqJyBoRWS8i9+Sw/2QRmSMiK0TkKxGp421vLiLfichP\n3r7ekb6AXLEUDIZhGEcRUPRFpCTwInAhkAD0EZGEbMVGA5NVtRnwCPC4t/0Q0F9VGwPdgHEiUiVS\nxueJZdg0DMM4imB6+q2B9aq6QVWPAFOBHtnKJABzvffzfPtVda2qrvPebwV+B2pGwvCAWE/fMAzj\nKIIR/drAJr/Pm71t/iQDPb33lwMVRSSLQ11EWgNlgF+yn0BEhojIYhFZvHPnzmBtzxvz6RuGYRxF\npAZy7wQ6isgyoCOwBUj37RSRWsCbwEBVzch+sKpOUNUkVU2qWTMCDwK+DJvW0zcMw8hCqSDKbAFO\n8vtcx9uWiee66QkgIhWAK1R1r/e5EvAJcL+qfh8JowNiGTYNwzByJJie/iLgdBGpLyJlgKuBD/0L\niEgNEfHVdS8w0dteBpiJG+SdETmzA2CzcQ3DMHIkoOirahowFPgcWA1MV9WfROQREenuFesErBGR\ntcDxwChv+1XAOcAAEVnuvZpH+iKOwvLuGIZh5Egw7h1UdRYwK9u2B/3ezwCO6smr6lvAW/m0MXQs\nw6ZhGEaOxOaMXHPvGIZh5Ehsi7719A3DMLIQm6JvGTYNwzByJDZF3zJsGoZh5Ejsir758w3DMI4i\nNkXfkq0ZhmHkSGyKvqVgMAzDyJHYFX1z7xiGYRxF7Iq+9fQNwzCOIvZE3zJsGoZh5Ersib4vw6a5\ndwzDMI4iqNw7UYXNxjViiL/++ovNmzdz+PDhojbFKCaULVuWOnXqULp06bCOjz3Rt2RrRgyxefNm\nKlasSL169RCRojbHKGJUld27d7N582bq168fVh2x596xnr4RQxw+fJjq1aub4BsAiAjVq1fP15Nf\n7Iq++fSNGMEE3/Anv9+H2BN9c+8YhmHkSuyJvrl3DCNi7N69m+bNm9O8eXNOOOEEateunfn5yJEj\nQdUxcOBA1qxZk2eZF198kbfffjsSJhsBiL2B3JQUqFABypQpaksMI+qpXr06y5cvB+Chhx6iQoUK\n3HnnnVnKqCqqSokSOfchJ02aFPA8t9xyS/6NLWTS0tIoVSr6JDQ2e/rWyzdikeHDoVOnyL6GDw/L\nlPXr15OQkEC/fv1o3Lgx27ZtY8iQISQlJdG4cWMeeeSRzLLt27dn+fLlpKWlUaVKFe655x4SExM5\n66yz+P333wH417/+xbhx4zLL33PPPbRu3ZoGDRrw7bffAnDw4EGuuOIKEhIS6NWrF0lJSZk3JH9G\njhxJq1ataNKkCTfeeCOqCsDatWvp0qULiYmJtGjRgo0bNwLw2GOP0bRpUxITE7n//vuz2Aywfft2\nTjvtNABeffVVLrvsMjp37swFF1zAvn376NKlCy1atKBZs2Z8/PHHmXZMmjSJZs2akZiYyMCBA0lN\nTeWUU04hLS0NgD179mT5XFjEnuhbhk3DKBR+/vlnRowYwapVq6hduzZPPPEEixcvJjk5mS+//JJV\nq1YddUxqaiodO3YkOTmZs846i4kTJ+ZYt6qycOFCnn766cwbyPPPP88JJ5zAqlWreOCBB1i2bFmO\nx952220sWrSIlStXkpqaymeffQZAnz59GDFiBMnJyXz77bccd9xxfPTRR3z66acsXLiQ5ORk7rjj\njoDXvWzZMv773/8yZ84cypUrx/vvv8/SpUuZPXs2I0aMACA5OZknn3ySr776iuTkZMaMGUPlypVp\n165dpj1TpkzhyiuvLPSnheh7NgmEJVszYhWvJ1xcOPXUU0lKSsr8PGXKFF577TXS0tLYunUrq1at\nIiEhIcsx5cqV48ILLwSgZcuWfP311znW3bNnz8wyvh75ggULuPvuuwFITEykcePGOR47Z84cnn76\naQ4fPsyuXbto2bIlbdu2ZdeuXVx66aWAm+AEMHv2bK677jrKlSsHQLUgOoznn38+Vb1V+VSVe+65\nhwULFlCiRAk2bdrErl27mDt3Lr17986sz/d30KBBPPfcc1xyySVMmjSJN998M+D5Ik3s9fTNvWMY\nhcKxxx6b+X7dunU8++yzzJ07lxUrVtCtW7ccY8nL+I21lSxZMlfXxjHeqnd5lcmJQ4cOMXToUGbO\nnMmKFSu47rrrwoppL1WqFBkZGQBHHe9/3ZMnTyY1NZWlS5eyfPlyatSokef5OnbsyNq1a5k3bx6l\nS5emYcOGIduWX2JP9M29YxiFzr59+6hYsSKVKlVi27ZtfP755xE/R7t27Zg+fToAK1euzNF99Mcf\nf1CiRAlq1KjB/v37ee+99wCoWrUqNWvW5KOPPgKckB86dIiuXbsyceJE/vjjDwBSvOi/evXqsWTJ\nEgBmzJiRq02pqakcd9xxlCpVii+//JItW7YA0KVLF6ZNm5ZZn+8vwDXXXEO/fv0YOHBgvtojXGJL\n9C3DpmEUCS1atCAhIYGGDRvSv39/2rVrF/FzDBs2jC1btpCQkMDDDz9MQkIClStXzlKmevXqXHvt\ntSQkJHDhhRfSpk2bzH1vv/02Y8aMoVmzZrRv356dO3dyySWX0K1bN5KSkmjevDnPPPMMAHfddRfP\nPvssLVq0YM+ePbna9I9//INvv/2Wpk2bMnXqVE4//XTAuZ/++c9/cs4559C8eXPuuuuuzGP69etH\namoqvXv3jmTzBI34RraLC0lJSbp48eLwDt63DypXhtGjIYgBGcMo7qxevZpGjRoVtRnFgrS0NNLS\n0ihbtizr1q3j/PPPZ926dVEXNjl16lQ+//zzoEJZcyOn74WILFHVpFwOySS6WisQNjHLMGKWAwcO\ncO6555KWloaq8vLLL0ed4N90003Mnj07M4KnKIiuFguEpWAwjJilSpUqmX72aGX8+PFFbUKM+fQt\n2ZphGEaexKboW0/fMAwjR4ISfRHpJiJrRGS9iNyTw/6TRWSOiKwQka9EpI7fvmtFZJ33ujaSxh+F\nuXcMwzDyJKDoi0hJ4EXgQiAB6CMiCdmKjQYmq2oz4BHgce/YasBIoA3QGhgpIlUjZ342rKdvGIaR\nJ8H09FsD61V1g6oeAaYCPbKVSQDmeu/n+e2/APhSVVNUdQ/wJdAt/2bngmXYNIyI0rlz56MmWo0b\nN46bbropz+MqVKgAwNatW+nVq1eOZTp16kSg8Oxx48Zx6NChzM8XXXQRe/fuDcZ0IxeCEf3awCa/\nz5u9bf4kAz2995cDFUWkepDHRg6bjWsYEaVPnz5MnTo1y7apU6fSp0+foI4/8cQT85zRGojsoj9r\n1iyqVKkSdn2FjapmpnMoLkRqIPdOoKOILAM6AluA9GAPFpEhIrJYRBbv3LkzfCss2ZoRwxRFZuVe\nvXrxySefZC6YsnHjRrZu3UqHDh0y4+ZbtGhB06ZN+eCDD446fuPGjTRp0gRwKRKuvvpqGjVqxOWX\nX56Z+gBc/LovLfPIkSMBeO6559i6dSudO3emc+fOgEuPsGvXLgDGjh1LkyZNaNKkSWZa5o0bN9Ko\nUSMGDx5M48aNOf/887Ocx8dHH31EmzZtOPPMMznvvPPYsWMH4OYCDBw4kKZNm9KsWbPMNA6fffYZ\nLVq0IDExkXPPPRdw6wuMHj06s84mTZqwceNGNm7cSIMGDejfvz9NmjRh06ZNOV4fwKJFizj77LNJ\nTEykdevW7N+/n3POOSdLyuj27duTnJyc9z8qBIKJ098CnOT3uY63LRNV3YrX0xeRCsAVqrpXRLYA\nnbId+1X2E6jqBGACuBm5wZufDUvBYBgRpVq1arRu3ZpPP/2UHj16MHXqVK666ipEhLJlyzJz5kwq\nVarErl27aNu2Ld27d891Ddfx48dTvnx5Vq9ezYoVK2jRokXmvlGjRlGtWjXS09M599xzWbFiBbfe\neitjx45l3rx51KhRI0tdS5YsYdKkSfzwww+oKm3atKFjx45UrVqVdevWMWXKFF555RWuuuoq3nvv\nPa655posx7dv357vv/8eEeHVV1/lqaeeYsyYMTz66KNUrlyZlStXAi7n/c6dOxk8eDDz58+nfv36\nWfLo5Ma6det44403aNu2ba7X17BhQ3r37s20adNo1aoV+/bto1y5clx//fW8/vrrjBs3jrVr13L4\n8GESExND+r/lRTCivwg4XUTq48T+aqCvfwERqQGkqGoGcC/gS5L9OfCY3+Dt+d7+giElBZo2LbDq\nDaMoKarMyj4Xj0/0X3vtNcC5Lu677z7mz59PiRIl2LJlCzt27OCEE07IsZ758+dz6623AtCsWTOa\nNWuWuW/69OlMmDCBtLQ0tm3bxqpVq7Lsz86CBQu4/PLLMzNe9uzZk6+//pru3btTv359mjdvDmRN\nzezP5s2b6d27N9u2bePIkSPUr18fcKmW/d1ZVatW5aOPPuKcc87JLBNM+uWTTz45U/Bzuz4RoVat\nWrRq1QqASpUqAXDllVfy6KOP8vTTTzNx4kQGDBgQ8HyhENC9o6ppwFCcgK8GpqvqTyLyiIh094p1\nAtaIyFrgeGCUd2wK8CjuxrEIeMTbVjCYT98wIk6PHj2YM2cOS5cu5dChQ7Rs2RJwCcx27tzJkiVL\nWL58Occff3xYaYx//fVXRo8ezZw5c1ixYgUXX3xxWPX48KVlhtxTMw8bNoyhQ4eycuVKXn755Xyn\nX4asKZj90y+Hen3ly5ena9eufPDBB0yfPp1+/fqFbFteBOXTV9VZqnqGqp6qqj5Bf1BVP/Tez1DV\n070yg1T1T79jJ6rqad4r/AxDgY00n75hFAAVKlSgc+fOXHfddVkGcH1phUuXLs28efP47bff8qzn\nnHPO4Z133gHgxx9/ZMWKFYBLy3zsscdSuXJlduzYwaeffpp5TMWKFdm/f/9RdXXo0IH333+fQ4cO\ncfDgQWbOnEmHDh2CvqbU1FRq13YxJW+88Ubm9q5du/Liiy9mft6zZw9t27Zl/vz5/Prrr0DW9MtL\nly4FYOnSpZn7s5Pb9TVo0IBt27axaNEiAPbv3595gxo0aBC33norrVq1ylywJVLEzozc/fshPd16\n+oZRAPTp04fk5OQsot+vXz8WL15M06ZNmTx5csAFQW666SYOHDhAo0aNePDBBzOfGBITEznzzDNp\n2LAhffv2zZKWeciQIXTr1i1zINdHixYtGDBgAK1bt6ZNmzYMGjSIM888M+jreeihh7jyyitp2bJl\nlvGCf/3rX+zZs4cmTZqQmJjIvHnzqFmzJhMmTKBnz54kJiZmpkS+4oorSElJoXHjxrzwwgucccYZ\nOZ4rt+srU6YM06ZNY9iwYSQmJtK1a9fMJ4CWLVtSqVKlAsm5HzuplVNS4OabYeBAuOCCyBtmGEWA\npVaOT7Zu3UqnTp34+eefKVHi6L55flIrx05Pv1o1mDrVBN8wjKhm8uTJtGnThlGjRuUo+PkltlIr\nG4ZhRDn9+/enf//+BVZ/7PT0DSNGKW4uWKNoye/3wUTfMIoxZcuWZffu3Sb8BuAEf/fu3ZQtWzbs\nOsy9YxjFmDp16rB582bylZ7EiCnKli1LnTp1AhfMBRN9wyjGlC5dOnMmqGFEAnPvGIZhxBEm+oZh\nGHGEib5hGEYcUexm5IrITiDvJB55UwPYFSFzCptoth2i2/5oth2i2/5oth2Kj/0nq2rNQIWKnejn\nFxFZHMxU5OJINNsO0W1/NNsO0W1/NNsO0We/uXcMwzDiCBN9wzCMOCIWRX9CURuQD6LZdohu+6PZ\ndohu+6PZdogy+2POp28YhmHkTiz29A3DMIxcMNE3DMOII2JG9EWkm4isEZH1InJPUdsTKiKyUURW\nishyEQlj6bDCRUQmisjvIvKj37ZqIvKliKzz/kZ2cc8IkYvtD4nIFq/9l4vIRUVpY26IyEkiMk9E\nVonITyJym7c9Wto+N/uLffuLSFkRWSgiyZ7tD3vb64vID572TBORMkVta17EhE9fREoCa4GuwGZg\nEdBHVVcVqWEhICIbgSRVLQ6TPAIiIucAB4DJqtrE2/YUkKKqT3g33qqqendR2pkTudj+EHBAVUcX\npW2BEJFaQC1VXSoiFYElwGXAAKKj7XOz/yqKefuLiADHquoBESkNLABuA24H/quqU0XkJSBZVccX\npa15ESs9/dbAelXdoKpHgKlAjyK2KaZR1flASrbNPYA3vPdv4H7MxY5cbI8KVHWbqi713u8HVgO1\niZ62z83+Yo86DngfS3svBboAM7ztxbbtfcSK6NcGNvl93kyUfJH8UOALEVkiIkOK2pgwOV5Vt3nv\ntwPHF6UxYTBURFZ47p9i6R7xR0TqAWcCPxCFbZ/NfoiC9heRkiKyHPgd+BL4BdirqmlekWKvPbEi\n+rFAe1VtAVwI3OK5IKIWdX7DaPIdjgdOBZoD24AxRWtO3ohIBeA9YLiq7vPfFw1tn4P9UdH+qpqu\nqs2BOjgPQ8MiNilkYkX0twAn+X2u422LGlR1i/f3d2Am7gsVbezwfLY+3+3vRWxP0KjqDu8HnQG8\nQjFuf8+f/B7wtqr+19scNW2fk/3R1P4AqroXmAecBVQREd+CVMVee2JF9BcBp3uj6GWAq4EPi9im\noBGRY71BLUTkWOB84Me8jyqWfAhc672/FvigCG0JCZ9gelxOMW1/bzDxNWC1qo712xUVbZ+b/dHQ\n/iJSU0SqeO/L4QJHVuPEv5dXrNi2vY+YiN4B8EK8xgElgYmqOqqITQoaETkF17sHt4TlO8XdfhGZ\nAnTCpZXdAYwE3gemA3Vx6bGvUtViN2Cai+2dcK4FBTYCN/j5yIsNItIe+BpYCWR4m+/D+cWjoe1z\ns78Pxbz9RaQZbqC2JK7DPF1VH/F+v1OBasAy4BpV/bPoLM2bmBF9wzAMIzCx4t4xDMMwgsBE3zAM\nI44w0TcMw4gjTPQNwzDiCBN9wzCMOMJE3zAMI44w0TcMw4gj/h/nnuAsleE63QAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}